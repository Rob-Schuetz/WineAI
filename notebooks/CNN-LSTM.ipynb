{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN-LSTM\n",
    "\n",
    "Information..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../scripts')\n",
    "from CNN import CNNBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.layers import Input, Embedding, Concatenate, Dense, Flatten, Dropout, LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columbia valley-1999.csv; days missing weather: 12\n",
      "willamette valley-2018.csv; days missing weather: 3\n",
      "carneros-2000.csv; days missing weather: 10\n",
      "north coast-2000.csv; days missing weather: 17\n",
      "columbia valley-1997.csv; days missing weather: 174\n",
      "RRV-2000.csv; days missing weather: 17\n",
      "sonoma-2000.csv; days missing weather: 17\n",
      "napa-2000.csv; days missing weather: 10\n"
     ]
    }
   ],
   "source": [
    "combos = os.listdir('../data/complete_weather')\n",
    "complete_combos = []\n",
    "count=0\n",
    "for c in combos:\n",
    "    pth = os.path.join('..', 'data', 'complete_weather', c)\n",
    "    df = pd.read_csv(pth)\n",
    "    n_missing = df.shape[0] - df.dropna().shape[0]\n",
    "    if n_missing == 0:\n",
    "        complete_combos.append(c)\n",
    "    elif df.shape[0] == n_missing:\n",
    "        count += 1\n",
    "    else:\n",
    "        print(c + '; days missing weather: ' + str(n_missing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(188, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skin</th>\n",
       "      <th>file</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>RRV-2008.csv</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>RRV-2020.csv</td>\n",
       "      <td>92.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>RRV-2009.csv</td>\n",
       "      <td>88.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>sonoma-2009.csv</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>sonoma-2009.csv</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   skin             file  quality\n",
       "0     1     RRV-2008.csv     91.0\n",
       "1     1     RRV-2020.csv     92.5\n",
       "5     1     RRV-2009.csv     88.5\n",
       "6     0  sonoma-2009.csv     88.0\n",
       "7     1  sonoma-2009.csv     91.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/wine_data_final.csv')\n",
    "df = df[df.file.isin(complete_combos)]\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(34)\n",
    "ids = set(df.index.tolist())\n",
    "test = set(df.sample(n=20).index.tolist())\n",
    "train = ids - test\n",
    "val = set(df.loc[ids, :].sample(n=15).index.tolist())\n",
    "train = train - val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.loc[train, :]\n",
    "df_val = df.loc[val, :]\n",
    "df_test = df.loc[test, :]\n",
    "\n",
    "s_train = df_train.skin.values\n",
    "gt_train = df_train.quality.values\n",
    "\n",
    "s_val = df_val.skin.values\n",
    "gt_val = df_val.quality.values\n",
    "\n",
    "s_test = df_test.skin.values\n",
    "gt_test = df_test.quality.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_weather(x):\n",
    "    pth = os.path.join('..', 'data', 'complete_weather', x)\n",
    "    weather = pd.read_csv(pth)\n",
    "    return weather.values\n",
    "\n",
    "def compile_weather(data, xs):\n",
    "    for i, x in enumerate(xs):\n",
    "        f = data.loc[x, 'file']\n",
    "        if i == 0:\n",
    "            n1 = fetch_weather(f)\n",
    "        else:\n",
    "            n2 = fetch_weather(f)\n",
    "            n1 = np.concatenate((n1, n2), axis=0)\n",
    "    return n1.reshape(i+1,245,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_train = compile_weather(df, train)\n",
    "w_val = compile_weather(df, val)\n",
    "w_test = compile_weather(df, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-3\n",
    "decay = ExponentialDecay(lr, decay_steps=1000, decay_rate=0.98)\n",
    "adam_decay = Adam(decay)\n",
    "\n",
    "earlystopping = EarlyStopping(min_delta=0.0, patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_input = Input(shape=(245,7))\n",
    "\n",
    "cnn = CNNBlock()\n",
    "x = cnn(weather_input)\n",
    "x = LSTM(8, activation='relu')(x)\n",
    "x = Dense(1, activation='relu')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=weather_input, outputs=x)\n",
    "model.compile(loss='mean_squared_error', optimizer=adam_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train / Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "5/5 [==============================] - 1s 108ms/step - loss: 44569.8047 - val_loss: 4736.3525\n",
      "Epoch 2/1000\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 4649.9458 - val_loss: 2971.4846\n",
      "Epoch 3/1000\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 2033.9988 - val_loss: 764.2705\n",
      "Epoch 4/1000\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 337.8019 - val_loss: 636.6532\n",
      "Epoch 5/1000\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 571.7006 - val_loss: 223.5692\n",
      "Epoch 6/1000\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 127.5964 - val_loss: 275.8088\n",
      "Epoch 7/1000\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 240.0989 - val_loss: 113.0948\n",
      "Epoch 8/1000\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 88.7989 - val_loss: 195.6386\n",
      "Epoch 9/1000\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 127.4701 - val_loss: 99.6286\n",
      "Epoch 10/1000\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 77.0360 - val_loss: 107.5661\n",
      "Epoch 11/1000\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 77.7026 - val_loss: 92.7613\n",
      "Epoch 12/1000\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 67.4734 - val_loss: 115.8202\n",
      "Epoch 13/1000\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 70.2152 - val_loss: 90.4884\n",
      "Epoch 14/1000\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 67.1960 - val_loss: 90.6975\n",
      "Epoch 15/1000\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 65.4894 - val_loss: 97.2321\n",
      "Epoch 16/1000\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 64.2853 - val_loss: 90.3542\n",
      "Epoch 17/1000\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 61.9777 - val_loss: 87.7117\n",
      "Epoch 18/1000\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 62.6143 - val_loss: 90.3213\n",
      "Epoch 19/1000\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 63.3697 - val_loss: 89.3072\n",
      "Epoch 20/1000\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 60.6373 - val_loss: 85.3210\n",
      "Epoch 21/1000\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 60.5110 - val_loss: 86.5931\n",
      "Epoch 22/1000\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 59.8551 - val_loss: 85.4567\n",
      "Epoch 23/1000\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 58.8901 - val_loss: 85.5541\n",
      "Epoch 24/1000\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 58.4475 - val_loss: 82.2599\n",
      "Epoch 25/1000\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 58.5172 - val_loss: 81.8971\n",
      "Epoch 26/1000\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 57.1006 - val_loss: 82.8659\n",
      "Epoch 27/1000\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 57.0319 - val_loss: 82.0137\n",
      "Epoch 28/1000\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 57.8895 - val_loss: 78.4370\n",
      "Epoch 29/1000\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 56.3108 - val_loss: 79.8814\n",
      "Epoch 30/1000\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 55.6657 - val_loss: 78.2609\n",
      "Epoch 31/1000\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 54.6244 - val_loss: 78.4172\n",
      "Epoch 32/1000\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 54.0265 - val_loss: 75.1486\n",
      "Epoch 33/1000\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 54.5556 - val_loss: 75.5813\n",
      "Epoch 34/1000\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 52.9466 - val_loss: 73.2397\n",
      "Epoch 35/1000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 52.2979 - val_loss: 75.2133\n",
      "Epoch 36/1000\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 52.4591 - val_loss: 72.0302\n",
      "Epoch 37/1000\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 51.3412 - val_loss: 71.2045\n",
      "Epoch 38/1000\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 50.5509 - val_loss: 69.5531\n",
      "Epoch 39/1000\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 50.3746 - val_loss: 69.8347\n",
      "Epoch 40/1000\n",
      "5/5 [==============================] - 1s 104ms/step - loss: 54.5974 - val_loss: 66.7465\n",
      "Epoch 41/1000\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 48.9353 - val_loss: 67.6912\n",
      "Epoch 42/1000\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 48.0993 - val_loss: 68.2008\n",
      "Epoch 43/1000\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 47.8039 - val_loss: 63.3424\n",
      "Epoch 44/1000\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 50.5697 - val_loss: 63.7934\n",
      "Epoch 45/1000\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 50.1008 - val_loss: 63.1204\n",
      "Epoch 46/1000\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 45.8678 - val_loss: 59.9541\n",
      "Epoch 47/1000\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 44.8760 - val_loss: 65.2745\n",
      "Epoch 48/1000\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 45.6119 - val_loss: 58.2315\n",
      "Epoch 49/1000\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 43.2322 - val_loss: 59.4674\n",
      "Epoch 50/1000\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 43.4678 - val_loss: 54.8185\n",
      "Epoch 51/1000\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 46.0059 - val_loss: 55.1064\n",
      "Epoch 52/1000\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 45.6243 - val_loss: 53.1749\n",
      "Epoch 53/1000\n",
      "5/5 [==============================] - 0s 91ms/step - loss: 42.9567 - val_loss: 50.9850\n",
      "Epoch 54/1000\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 40.5912 - val_loss: 52.2786\n",
      "Epoch 55/1000\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 38.4711 - val_loss: 49.0062\n",
      "Epoch 56/1000\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 38.0440 - val_loss: 49.8122\n",
      "Epoch 57/1000\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 37.1967 - val_loss: 46.0478\n",
      "Epoch 58/1000\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 36.3714 - val_loss: 45.6095\n",
      "Epoch 59/1000\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 35.1319 - val_loss: 46.9375\n",
      "Epoch 60/1000\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 34.2837 - val_loss: 40.9758\n",
      "Epoch 61/1000\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 34.4685 - val_loss: 44.8072\n",
      "Epoch 62/1000\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 34.6381 - val_loss: 39.0027\n",
      "Epoch 63/1000\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 33.5508 - val_loss: 38.1118\n",
      "Epoch 64/1000\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 33.9436 - val_loss: 40.3777\n",
      "Epoch 65/1000\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 30.9465 - val_loss: 34.9051\n",
      "Epoch 66/1000\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 29.2442 - val_loss: 33.4675\n",
      "Epoch 67/1000\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 28.6326 - val_loss: 33.7417\n",
      "Epoch 68/1000\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 28.7313 - val_loss: 36.8174\n",
      "Epoch 69/1000\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 27.1923 - val_loss: 27.9667\n",
      "Epoch 70/1000\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 27.2817 - val_loss: 41.2571\n",
      "Epoch 71/1000\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 27.4715 - val_loss: 25.6092\n",
      "Epoch 72/1000\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 26.0611 - val_loss: 31.0487\n",
      "Epoch 73/1000\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 25.0482 - val_loss: 23.6948\n",
      "Epoch 74/1000\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 28.5892 - val_loss: 22.2234\n",
      "Epoch 75/1000\n",
      "5/5 [==============================] - 0s 95ms/step - loss: 25.6284 - val_loss: 37.3974\n",
      "Epoch 76/1000\n",
      "5/5 [==============================] - 1s 102ms/step - loss: 25.0390 - val_loss: 21.8197\n",
      "Epoch 77/1000\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 21.0746 - val_loss: 26.2754\n",
      "Epoch 78/1000\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 20.5025 - val_loss: 20.4092\n",
      "Epoch 79/1000\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 20.5632 - val_loss: 18.3590\n",
      "Epoch 80/1000\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 20.4656 - val_loss: 23.9242\n",
      "Epoch 81/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 68ms/step - loss: 19.3089 - val_loss: 17.5000\n",
      "Epoch 82/1000\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 20.8289 - val_loss: 15.2023\n",
      "Epoch 83/1000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 20.3792 - val_loss: 23.5462\n",
      "Epoch 84/1000\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 19.0187 - val_loss: 18.6293\n",
      "Epoch 85/1000\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 17.1563 - val_loss: 16.2430\n",
      "Epoch 86/1000\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 16.9535 - val_loss: 16.1219\n",
      "Epoch 87/1000\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 16.8899 - val_loss: 24.9781\n",
      "Epoch 88/1000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 17.5076 - val_loss: 15.7191\n",
      "Epoch 89/1000\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 17.6039 - val_loss: 12.6005\n",
      "Epoch 90/1000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 21.1170 - val_loss: 22.3294\n",
      "Epoch 91/1000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 16.3150 - val_loss: 18.5480\n",
      "Epoch 92/1000\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 15.3811 - val_loss: 13.5262\n",
      "Epoch 93/1000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 15.2671 - val_loss: 20.4611\n",
      "Epoch 94/1000\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 15.9478 - val_loss: 18.2229\n",
      "Epoch 95/1000\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 15.3784 - val_loss: 11.4098\n",
      "Epoch 96/1000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 16.8739 - val_loss: 17.5097\n",
      "Epoch 97/1000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 14.5389 - val_loss: 14.3716\n",
      "Epoch 98/1000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 14.5256 - val_loss: 17.4676\n",
      "Epoch 99/1000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 14.2849 - val_loss: 12.7475\n",
      "Epoch 100/1000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 15.0428 - val_loss: 19.1630\n",
      "Epoch 101/1000\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 14.5314 - val_loss: 14.4529\n",
      "Epoch 102/1000\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 14.7024 - val_loss: 11.5787\n",
      "Epoch 103/1000\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 15.5976 - val_loss: 11.9937\n",
      "Epoch 104/1000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 14.0406 - val_loss: 23.6552\n",
      "Epoch 105/1000\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 14.6457 - val_loss: 9.8801\n",
      "Epoch 106/1000\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 13.9311 - val_loss: 33.0237\n",
      "Epoch 107/1000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 16.2358 - val_loss: 11.8883\n",
      "Epoch 108/1000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 15.4121 - val_loss: 9.8493\n",
      "Epoch 109/1000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 16.2304 - val_loss: 12.7862\n",
      "Epoch 110/1000\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 14.3566 - val_loss: 10.6418\n",
      "Epoch 111/1000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 13.9905 - val_loss: 15.4910\n",
      "Epoch 112/1000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 13.9571 - val_loss: 25.4334\n",
      "Epoch 113/1000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 16.9251 - val_loss: 16.8636\n",
      "Epoch 114/1000\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 15.0273 - val_loss: 10.0329\n",
      "Epoch 115/1000\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 15.7530 - val_loss: 21.7539\n",
      "Epoch 116/1000\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 19.2575 - val_loss: 26.2205\n",
      "Epoch 117/1000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 16.7691 - val_loss: 24.1282\n",
      "Epoch 118/1000\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 15.1137 - val_loss: 16.2665\n",
      "Epoch 119/1000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 14.9279 - val_loss: 9.9108\n",
      "Epoch 120/1000\n",
      "5/5 [==============================] - 0s 84ms/step - loss: 16.3504 - val_loss: 13.6055\n",
      "Epoch 121/1000\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 13.8804 - val_loss: 19.9898\n",
      "Epoch 122/1000\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 13.4012 - val_loss: 11.0824\n",
      "Epoch 123/1000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 13.6039 - val_loss: 13.4720\n",
      "Epoch 124/1000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 13.5219 - val_loss: 17.5540\n",
      "Epoch 125/1000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 13.3550 - val_loss: 9.8851\n",
      "Epoch 126/1000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 14.1131 - val_loss: 12.1749\n",
      "Epoch 127/1000\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 14.0982 - val_loss: 9.7950\n",
      "Epoch 128/1000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 17.6624 - val_loss: 11.7014\n",
      "Epoch 129/1000\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 13.8572 - val_loss: 14.5291\n",
      "Epoch 130/1000\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 13.9939 - val_loss: 15.6136\n",
      "Epoch 131/1000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 13.2090 - val_loss: 12.4770\n",
      "Epoch 132/1000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 13.6183 - val_loss: 9.3052\n",
      "Epoch 133/1000\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 19.5403 - val_loss: 11.8748\n",
      "Epoch 134/1000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 19.7956 - val_loss: 16.8655\n",
      "Epoch 135/1000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 24.0773 - val_loss: 62.1162\n",
      "Epoch 136/1000\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 20.9284 - val_loss: 10.0985\n",
      "Epoch 137/1000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 14.1136 - val_loss: 10.3606\n",
      "Epoch 138/1000\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 13.2814 - val_loss: 23.8103\n",
      "Epoch 139/1000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 14.1357 - val_loss: 14.6822\n",
      "Epoch 140/1000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 14.7194 - val_loss: 9.4526\n",
      "Epoch 141/1000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 14.9329 - val_loss: 11.3161\n",
      "Epoch 142/1000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 16.6612 - val_loss: 33.0236\n",
      "Epoch 143/1000\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 18.8608 - val_loss: 30.5074\n",
      "Epoch 144/1000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 16.8587 - val_loss: 10.7365\n",
      "Epoch 145/1000\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 13.6217 - val_loss: 9.6328\n",
      "Epoch 146/1000\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 13.3044 - val_loss: 19.8317\n",
      "Epoch 147/1000\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 12.9942 - val_loss: 10.7042\n",
      "Epoch 148/1000\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 13.0010 - val_loss: 20.8361\n",
      "Epoch 149/1000\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 14.1709 - val_loss: 21.1533\n",
      "Epoch 150/1000\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 14.9100 - val_loss: 13.4956\n",
      "Epoch 151/1000\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 14.4553 - val_loss: 9.9303\n",
      "Epoch 152/1000\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 13.9354 - val_loss: 10.4931\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9823f4e250>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=w_train, y=gt_train, validation_data=(w_val, gt_val),\n",
    "          epochs=1000, callbacks=[earlystopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = model.predict([s_test, w_test]).T[0]\n",
    "preds = model.predict(w_test).T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_lim(x):\n",
    "    if x > 100: \n",
    "        return 100\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pred</th>\n",
       "      <td>92.062668</td>\n",
       "      <td>92.652992</td>\n",
       "      <td>92.231796</td>\n",
       "      <td>88.723137</td>\n",
       "      <td>91.088913</td>\n",
       "      <td>91.742027</td>\n",
       "      <td>92.221329</td>\n",
       "      <td>91.360558</td>\n",
       "      <td>88.821381</td>\n",
       "      <td>95.208153</td>\n",
       "      <td>94.938293</td>\n",
       "      <td>88.794884</td>\n",
       "      <td>92.947952</td>\n",
       "      <td>94.501366</td>\n",
       "      <td>93.932144</td>\n",
       "      <td>90.500908</td>\n",
       "      <td>85.332619</td>\n",
       "      <td>88.594841</td>\n",
       "      <td>90.290726</td>\n",
       "      <td>84.497314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true</th>\n",
       "      <td>92.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>94.500000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>86.500000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>92.500000</td>\n",
       "      <td>92.500000</td>\n",
       "      <td>86.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0          1          2          3          4          5   \\\n",
       "pred  92.062668  92.652992  92.231796  88.723137  91.088913  91.742027   \n",
       "true  92.000000  90.000000  89.000000  93.000000  94.000000  94.500000   \n",
       "\n",
       "             6          7          8          9          10         11  \\\n",
       "pred  92.221329  91.360558  88.821381  95.208153  94.938293  88.794884   \n",
       "true  90.000000  94.000000  89.000000  95.000000  92.000000  86.500000   \n",
       "\n",
       "             12         13         14         15         16         17  \\\n",
       "pred  92.947952  94.501366  93.932144  90.500908  85.332619  88.594841   \n",
       "true  93.000000  93.000000  94.000000  91.000000  85.000000  92.500000   \n",
       "\n",
       "             18         19  \n",
       "pred  90.290726  84.497314  \n",
       "true  92.500000  86.000000  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.DataFrame({'pred':preds, 'true': gt_test})\n",
    "res.pred = res.pred.apply(pred_lim)\n",
    "res.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(res.pred, res.true)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr, _ = pearsonr(res.pred, res.true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6880012799169649"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2665592350707127"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.sum((res.pred - res.true)**2)/res.shape[0])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dbc0770ecd30f98561162093fd8abab0709c5060f2f81711c403a4cebee6fe13"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
